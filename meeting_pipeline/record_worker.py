#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¼šè®®è®°å½•å¤„ç†ç³»ç»Ÿ
ç«¯åˆ°ç«¯æµæ°´çº¿ï¼šè…¾è®¯ä¼šè®®API â†’ Kimi ASR/LLM â†’ MySQLå­˜å‚¨
"""

import os
import time
import json
import requests
import pymysql
import tempfile
import subprocess
from datetime import datetime, timedelta
from urllib.parse import urlencode
from dotenv import load_dotenv
import base64
import hmac
import hashlib

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# è…¾è®¯ä¼šè®®APIé…ç½®
APP_ID = "233276242"
SDK_ID = "27370101959"
SECRET_ID = "juh9DMb5FHRTzSxd74xqt2LeSyVhbb3q"
SECRET_KEY = "RjAk20VrzQKshN4IdWypShP95RdJ2hE8aYERA80cZFsc12Ie"
API_BASE = "https://api.meeting.qq.com"

# Kimi APIé…ç½®
KIMI_API_KEY = "sk-reaTT6uRqEqQPZ7HMXp5gmoingV6cZ2dumU8Y4axl9DHN2Jw"
KIMI_BASE_URL = "https://api.moonshot.cn/v1"

# æ•°æ®åº“é…ç½®
DB_CONFIG = {
    'host': os.getenv('DB_HOST', '127.0.0.1'),
    'port': int(os.getenv('DB_PORT', 3306)),
    'user': os.getenv('DB_USER', 'meeting'),
    'password': os.getenv('DB_PASS', 'VeryStrongPwd'),
    'database': os.getenv('DB_NAME', 'meeting_db'),
    'charset': 'utf8mb4'
}

def generate_signature(method, uri, body=""):
    """ç”Ÿæˆè…¾è®¯ä¼šè®®APIç­¾å"""
    ts = str(int(time.time()))
    nonce = str(int(time.time() * 1000))
    
    # æŒ‰ASCIIå‡åºæ’åˆ—æ‰€æœ‰å‚ä¸ç­¾åçš„header
    hl_items = [
        ("SdkId", SDK_ID),
        ("X-TC-Key", SECRET_ID),
        ("X-TC-Nonce", nonce),
        ("X-TC-Timestamp", ts)
    ]
    hl = "&".join(f"{k}={v}" for k, v in hl_items)
    
    sts = f"{method}\n{hl}\n{uri}\n{body}"
    signature = base64.b64encode(
        hmac.new(SECRET_KEY.encode(), sts.encode(), hashlib.sha256).digest()
    ).decode()
    
    return {
        "AppId": APP_ID,
        "SdkId": SDK_ID,
        "X-TC-Key": SECRET_ID,
        "X-TC-Nonce": nonce,
        "X-TC-Timestamp": ts,
        "X-TC-Signature": signature,
        "Content-Type": "application/json"
    }

def list_meeting_records(start_time, end_time, page=1, page_size=50):
    """è·å–ä¼šè®®å½•åˆ¶åˆ—è¡¨"""
    try:
        params = {
            "end_time": end_time,
            "page": page,
            "page_size": page_size,
            "start_time": start_time
        }
        uri = "/v1/corp/records?" + urlencode(sorted(params.items()))
        
        headers = generate_signature("GET", uri)
        response = requests.get(API_BASE + uri, headers=headers, timeout=10)
        
        if response.status_code == 200:
            return response.json()
        else:
            print(f"âŒ è·å–ä¼šè®®è®°å½•å¤±è´¥: {response.status_code} - {response.text}")
            return None
    except Exception as e:
        print(f"âŒ è·å–ä¼šè®®è®°å½•å¼‚å¸¸: {e}")
        return None

def get_record_download_url(record_id):
    """è·å–å½•åˆ¶æ–‡ä»¶ä¸‹è½½åœ°å€"""
    try:
        params = {"meeting_record_id": record_id}
        uri = "/v1/corp/addresses?" + urlencode(sorted(params.items()))
        
        headers = generate_signature("GET", uri)
        response = requests.get(API_BASE + uri, headers=headers, timeout=10)
        
        if response.status_code == 200:
            return response.json()
        else:
            print(f"âŒ è·å–ä¸‹è½½åœ°å€å¤±è´¥: {response.status_code} - {response.text}")
            return None
    except Exception as e:
        print(f"âŒ è·å–ä¸‹è½½åœ°å€å¼‚å¸¸: {e}")
        return None

def download_and_extract_audio(download_url, record_id):
    """ä¸‹è½½å¹¶æå–éŸ³é¢‘"""
    try:
        # ä¸‹è½½æ–‡ä»¶
        temp_dir = tempfile.mkdtemp()
        mp4_path = os.path.join(temp_dir, f"{record_id}.mp4")
        wav_path = os.path.join(temp_dir, f"{record_id}.wav")
        
        # ä½¿ç”¨aria2cä¸‹è½½
        subprocess.run([
            "aria2c", "-x", "8", "-o", f"{record_id}.mp4",
            download_url, "-d", temp_dir
        ], check=True)
        
        # ä½¿ç”¨ffmpegæå–éŸ³é¢‘
        subprocess.run([
            "ffmpeg", "-i", mp4_path, "-vn", "-ar", "16000", 
            "-ac", "1", wav_path
        ], check=True)
        
        return wav_path
    except Exception as e:
        print(f"âŒ éŸ³é¢‘å¤„ç†å¼‚å¸¸: {e}")
        return None

def kimi_asr_transcribe(audio_path):
    """ä½¿ç”¨Kimiè¿›è¡Œè¯­éŸ³è½¬å†™"""
    try:
        # è¯»å–éŸ³é¢‘æ–‡ä»¶
        with open(audio_path, 'rb') as f:
            audio_data = f.read()
        
        # è°ƒç”¨Kimi ASR API
        headers = {
            "Authorization": f"Bearer {KIMI_API_KEY}",
            "Content-Type": "audio/wav"
        }
        
        response = requests.post(
            f"{KIMI_BASE_URL}/audio/transcriptions",
            headers=headers,
            files={"file": audio_data},
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            return result.get("text", "")
        else:
            print(f"âŒ Kimi ASRå¤±è´¥: {response.status_code} - {response.text}")
            return ""
    except Exception as e:
        print(f"âŒ Kimi ASRå¼‚å¸¸: {e}")
        return ""

def kimi_summarize_and_classify(transcript):
    """ä½¿ç”¨Kimiè¿›è¡Œæ‘˜è¦å’Œåˆ†ç±»"""
    try:
        prompt = f"""
è¯·å¯¹ä»¥ä¸‹ä¼šè®®è®°å½•è¿›è¡Œæ‘˜è¦å’Œåˆ†ç±»ï¼š

ä¼šè®®å†…å®¹ï¼š
{transcript}

è¯·æä¾›ï¼š
1. 150å­—ä»¥å†…çš„æ‘˜è¦
2. ä¼šè®®ç±»å‹åˆ†ç±»ï¼ˆç®€å†ä¼˜åŒ–/é¡¹ç›®æ·±æŒ–/é¢è¯•æ¨¡æ‹Ÿ/Offeråç»­/å…¶ä»–ï¼‰

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼š
{{
    "summary": "æ‘˜è¦å†…å®¹",
    "phase": "åˆ†ç±»ç»“æœ"
}}
"""
        
        headers = {
            "Authorization": f"Bearer {KIMI_API_KEY}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": "moonshot-v1-8k",
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.7
        }
        
        response = requests.post(
            f"{KIMI_BASE_URL}/chat/completions",
            headers=headers,
            json=data,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            content = result["choices"][0]["message"]["content"]
            
            # è§£æJSONå“åº”
            try:
                parsed = json.loads(content)
                return parsed.get("summary", ""), parsed.get("phase", "å…¶ä»–")
            except:
                # å¦‚æœJSONè§£æå¤±è´¥ï¼Œè¿”å›é»˜è®¤å€¼
                return content[:150], "å…¶ä»–"
        else:
            print(f"âŒ Kimi LLMå¤±è´¥: {response.status_code} - {response.text}")
            return "", "å…¶ä»–"
    except Exception as e:
        print(f"âŒ Kimi LLMå¼‚å¸¸: {e}")
        return "", "å…¶ä»–"

def save_to_database(record_data):
    """ä¿å­˜åˆ°æ•°æ®åº“"""
    try:
        conn = pymysql.connect(**DB_CONFIG, autocommit=True)
        with conn.cursor() as cursor:
            sql = """
            INSERT INTO recordings (
                id, meeting_id, start_ts, end_ts, student_ids, 
                phase, transcript, summary, play_url, download_url
            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            ON DUPLICATE KEY UPDATE
                transcript = VALUES(transcript),
                summary = VALUES(summary),
                phase = VALUES(phase)
            """
            
            cursor.execute(sql, (
                record_data["id"],
                record_data["meeting_id"],
                record_data["start_ts"],
                record_data["end_ts"],
                json.dumps(record_data["student_ids"], ensure_ascii=False),
                record_data["phase"],
                record_data["transcript"],
                record_data["summary"],
                record_data["play_url"],
                record_data["download_url"]
            ))
            
            # æ›´æ–°å­¦ç”Ÿç»Ÿè®¡
            for student_id in record_data["student_ids"]:
                cursor.execute("""
                    INSERT INTO student_stats(student_id, record_cnt) 
                    VALUES(%s, 1) 
                    ON DUPLICATE KEY UPDATE record_cnt=record_cnt+1
                """, (student_id,))
        
        conn.close()
        print(f"âœ… è®°å½• {record_data['id']} å·²ä¿å­˜åˆ°æ•°æ®åº“")
        return True
    except Exception as e:
        print(f"âŒ æ•°æ®åº“ä¿å­˜å¼‚å¸¸: {e}")
        return False

def process_record(record_info):
    """å¤„ç†å•æ¡ä¼šè®®è®°å½•"""
    record_id = record_info["meeting_record_id"]
    print(f"ğŸ” å¤„ç†ä¼šè®®è®°å½•: {record_id}")
    
    # è·å–ä¸‹è½½åœ°å€
    download_info = get_record_download_url(record_id)
    if not download_info:
        print(f"âŒ æ— æ³•è·å–è®°å½• {record_id} çš„ä¸‹è½½åœ°å€")
        return False
    
    download_url = download_info["record_file_list"][0]["download_url"]
    play_url = download_info["record_file_list"][0]["play_url"]
    
    # ä¸‹è½½å¹¶æå–éŸ³é¢‘
    audio_path = download_and_extract_audio(download_url, record_id)
    if not audio_path:
        print(f"âŒ æ— æ³•å¤„ç†è®°å½• {record_id} çš„éŸ³é¢‘")
        return False
    
    # è¯­éŸ³è½¬å†™
    transcript = kimi_asr_transcribe(audio_path)
    if not transcript:
        print(f"âŒ æ— æ³•è½¬å†™è®°å½• {record_id} çš„éŸ³é¢‘")
        return False
    
    # æ‘˜è¦å’Œåˆ†ç±»
    summary, phase = kimi_summarize_and_classify(transcript)
    
    # å‡†å¤‡æ•°æ®
    record_data = {
        "id": record_id,
        "meeting_id": record_info["meeting_id"],
        "start_ts": datetime.fromtimestamp(record_info["start_time"]),
        "end_ts": datetime.fromtimestamp(record_info["end_time"]),
        "student_ids": [p["userid"] for p in record_info.get("attendees", [])],
        "phase": phase,
        "transcript": transcript,
        "summary": summary,
        "play_url": play_url,
        "download_url": download_url
    }
    
    # ä¿å­˜åˆ°æ•°æ®åº“
    return save_to_database(record_data)

def run_batch_processing(start_time, end_time):
    """æ‰¹é‡å¤„ç†ä¼šè®®è®°å½•"""
    print(f"ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç†: {datetime.fromtimestamp(start_time)} - {datetime.fromtimestamp(end_time)}")
    
    page = 1
    total_processed = 0
    
    while True:
        print(f"ğŸ“„ å¤„ç†ç¬¬ {page} é¡µ...")
        
        records_data = list_meeting_records(start_time, end_time, page, 50)
        if not records_data:
            print("âŒ æ— æ³•è·å–ä¼šè®®è®°å½•åˆ—è¡¨")
            break
        
        records = records_data.get("records", [])
        if not records:
            print("ğŸ“­ æ²¡æœ‰æ›´å¤šè®°å½•")
            break
        
        for record in records:
            if process_record(record):
                total_processed += 1
        
        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ›´å¤šé¡µ
        total_pages = records_data.get("total_pages", 1)
        if page >= total_pages:
            break
        page += 1
    
    print(f"âœ… æ‰¹é‡å¤„ç†å®Œæˆï¼Œå…±å¤„ç† {total_processed} æ¡è®°å½•")

def run_incremental_processing():
    """å¢é‡å¤„ç†ï¼ˆå¤„ç†æ˜¨å¤©çš„è®°å½•ï¼‰"""
    yesterday = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0) - timedelta(days=1)
    today = yesterday + timedelta(days=1)
    
    start_time = int(yesterday.timestamp())
    end_time = int(today.timestamp())
    
    print(f"ğŸ“… å¢é‡å¤„ç†: {yesterday.date()}")
    run_batch_processing(start_time, end_time)

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 2:
        # æŒ‡å®šæ—¶é—´èŒƒå›´
        start_time = int(sys.argv[1])
        end_time = int(sys.argv[2])
        run_batch_processing(start_time, end_time)
    else:
        # å¢é‡å¤„ç†
        run_incremental_processing() 