#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¼”ç¤ºå¤„ç†è„šæœ¬
ç”Ÿæˆæ¨¡æ‹Ÿçš„è…¾è®¯ä¼šè®®æ•°æ®ï¼Œå±•ç¤ºå®Œæ•´çš„æµæ°´çº¿æ•ˆæœ
"""

import os
import time
import json
import random
from datetime import datetime, timedelta
from dotenv import load_dotenv
import pymysql
from loguru import logger

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®æ—¥å¿—
logger.add("logs/demo_processing.log", rotation="1 day", retention="7 days", level="INFO")

# æ•°æ®åº“é…ç½®
DB_CONFIG = {
    'host': os.getenv("DB_HOST"),
    'port': int(os.getenv("DB_PORT", 3306)),
    'user': os.getenv("DB_USER"),
    'password': os.getenv("DB_PASS"),
    'database': os.getenv("DB_NAME"),
    'charset': 'utf8mb4'
}

# Kimi APIé…ç½®
KIMI_API_KEY = os.getenv("KIMI_API_KEY")
KIMI_BASE_URL = os.getenv("KIMI_BASE_URL", "https://kimi.moonshot.cn/api")

def generate_mock_meetings(count=10):
    """ç”Ÿæˆæ¨¡æ‹Ÿçš„ä¼šè®®æ•°æ®"""
    meetings = []
    
    # ä¼šè®®ç±»å‹
    phases = ['ç®€å†ä¼˜åŒ–', 'é¡¹ç›®æ·±æŒ–', 'é¢è¯•æ¨¡æ‹Ÿ', 'Offeråç»­', 'å…¶ä»–']
    
    # å­¦ç”ŸIDåˆ—è¡¨
    student_ids = [
        "student_001", "student_002", "student_003", "student_004", "student_005",
        "student_006", "student_007", "student_008", "student_009", "student_010"
    ]
    
    # æ•™å¸ˆIDåˆ—è¡¨
    teacher_ids = ["teacher_001", "teacher_002", "teacher_003"]
    
    # æ¨¡æ‹Ÿä¼šè®®å†…å®¹æ¨¡æ¿
    meeting_templates = [
        {
            "phase": "ç®€å†ä¼˜åŒ–",
            "transcript": "ä»Šå¤©æˆ‘ä»¬ä¸»è¦è®¨è®ºç®€å†ä¼˜åŒ–çš„é—®é¢˜ã€‚é¦–å…ˆï¼Œä½ çš„ç®€å†ç»“æ„éœ€è¦è°ƒæ•´ï¼ŒæŠŠæœ€é‡è¦çš„é¡¹ç›®ç»éªŒæ”¾åœ¨å‰é¢ã€‚å…¶æ¬¡ï¼Œæ¯ä¸ªé¡¹ç›®éƒ½è¦ç”¨STARæ³•åˆ™æ¥æè¿°ï¼Œå³æƒ…å¢ƒ(Situation)ã€ä»»åŠ¡(Task)ã€è¡ŒåŠ¨(Action)ã€ç»“æœ(Result)ã€‚æœ€åï¼Œç®€å†è¦çªå‡ºä½ çš„æŠ€æœ¯æ ˆå’Œæ ¸å¿ƒèƒ½åŠ›ã€‚",
            "summary": "ä¼šè®®ä¸»è¦è®¨è®ºäº†ç®€å†ä¼˜åŒ–çš„ä¸‰ä¸ªè¦ç‚¹ï¼šç»“æ„è°ƒæ•´ã€STARæ³•åˆ™åº”ç”¨ã€æŠ€æœ¯æ ˆçªå‡ºã€‚"
        },
        {
            "phase": "é¡¹ç›®æ·±æŒ–",
            "transcript": "å…³äºä½ çš„é¡¹ç›®ç»éªŒï¼Œæˆ‘ä»¬éœ€è¦æ·±å…¥æŒ–æ˜æŠ€æœ¯ç»†èŠ‚ã€‚è¿™ä¸ªç”µå•†ç³»ç»Ÿä½ ä½¿ç”¨äº†å“ªäº›æŠ€æœ¯æ ˆï¼Ÿæ•°æ®åº“è®¾è®¡æ˜¯å¦‚ä½•è€ƒè™‘çš„ï¼Ÿé«˜å¹¶å‘åœºæ™¯ä¸‹æ˜¯å¦‚ä½•å¤„ç†çš„ï¼Ÿç¼“å­˜ç­–ç•¥æ˜¯ä»€ä¹ˆï¼Ÿè¿™äº›éƒ½æ˜¯é¢è¯•å®˜ä¼šé‡ç‚¹å…³æ³¨çš„ã€‚",
            "summary": "æ·±å…¥è®¨è®ºäº†é¡¹ç›®æŠ€æœ¯ç»†èŠ‚ï¼ŒåŒ…æ‹¬æŠ€æœ¯æ ˆã€æ•°æ®åº“è®¾è®¡ã€é«˜å¹¶å‘å¤„ç†å’Œç¼“å­˜ç­–ç•¥ã€‚"
        },
        {
            "phase": "é¢è¯•æ¨¡æ‹Ÿ",
            "transcript": "ç°åœ¨å¼€å§‹é¢è¯•æ¨¡æ‹Ÿã€‚è¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚å¥½çš„ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬æ¨¡æ‹ŸæŠ€æœ¯é¢è¯•ç¯èŠ‚ã€‚è¯·è§£é‡Šä¸€ä¸‹ä»€ä¹ˆæ˜¯è®¾è®¡æ¨¡å¼ï¼Ÿå•ä¾‹æ¨¡å¼æœ‰å“ªäº›å®ç°æ–¹å¼ï¼Ÿçº¿ç¨‹å®‰å…¨å¦‚ä½•ä¿è¯ï¼Ÿè¿™äº›é—®é¢˜ä½ è¦å‡†å¤‡å……åˆ†ã€‚",
            "summary": "è¿›è¡Œäº†é¢è¯•æ¨¡æ‹Ÿï¼ŒåŒ…æ‹¬è‡ªæˆ‘ä»‹ç»å’ŒæŠ€æœ¯é¢è¯•ç¯èŠ‚ï¼Œé‡ç‚¹è®¨è®ºäº†è®¾è®¡æ¨¡å¼å’Œçº¿ç¨‹å®‰å…¨ã€‚"
        },
        {
            "phase": "Offeråç»­",
            "transcript": "æ­å–œä½ æ‹¿åˆ°äº†Offerï¼ç°åœ¨æˆ‘ä»¬æ¥è®¨è®ºåç»­çš„å‡†å¤‡å·¥ä½œã€‚å…¥èŒå‰éœ€è¦äº†è§£å…¬å¸çš„æŠ€æœ¯æ ˆï¼Œç†Ÿæ‚‰å›¢é˜Ÿçš„å·¥ä½œæµç¨‹ã€‚åŒæ—¶è¦å‡†å¤‡ä¸€äº›å…¥èŒåçš„å­¦ä¹ è®¡åˆ’ï¼Œå°½å¿«èå…¥å›¢é˜Ÿã€‚",
            "summary": "è®¨è®ºäº†Offeråç»­å‡†å¤‡å·¥ä½œï¼ŒåŒ…æ‹¬æŠ€æœ¯æ ˆäº†è§£ã€å·¥ä½œæµç¨‹ç†Ÿæ‚‰å’Œå­¦ä¹ è®¡åˆ’åˆ¶å®šã€‚"
        },
        {
            "phase": "å…¶ä»–",
            "transcript": "ä»Šå¤©æˆ‘ä»¬è®¨è®ºä¸€ä¸‹èŒä¸šè§„åˆ’çš„é—®é¢˜ã€‚çŸ­æœŸç›®æ ‡æ˜¯æŒæ¡æ ¸å¿ƒæŠ€æœ¯ï¼Œä¸­æœŸç›®æ ‡æ˜¯æˆä¸ºå›¢é˜Ÿçš„æŠ€æœ¯éª¨å¹²ï¼Œé•¿æœŸç›®æ ‡æ˜¯æŠ€æœ¯ç®¡ç†æˆ–è€…æ¶æ„å¸ˆæ–¹å‘ã€‚æ¯ä¸ªé˜¶æ®µéƒ½è¦æœ‰æ˜ç¡®çš„å­¦ä¹ è®¡åˆ’ã€‚",
            "summary": "è®¨è®ºäº†èŒä¸šè§„åˆ’ï¼ŒåŒ…æ‹¬çŸ­æœŸã€ä¸­æœŸå’Œé•¿æœŸç›®æ ‡çš„è®¾å®šå’Œå­¦ä¹ è®¡åˆ’ã€‚"
        }
    ]
    
    # ç”Ÿæˆæœ€è¿‘30å¤©çš„ä¼šè®®æ•°æ®
    end_time = datetime.now()
    start_time = end_time - timedelta(days=30)
    
    for i in range(count):
        # éšæœºé€‰æ‹©ä¼šè®®æ¨¡æ¿
        template = random.choice(meeting_templates)
        
        # éšæœºç”Ÿæˆä¼šè®®æ—¶é—´
        meeting_start = start_time + timedelta(
            days=random.randint(0, 30),
            hours=random.randint(9, 18),
            minutes=random.randint(0, 59)
        )
        meeting_end = meeting_start + timedelta(
            hours=random.randint(1, 3),
            minutes=random.randint(0, 59)
        )
        
        # éšæœºé€‰æ‹©å‚ä¸è€…
        participants = random.sample(student_ids, random.randint(1, 3))
        participants.extend(random.sample(teacher_ids, random.randint(1, 2)))
        
        meeting = {
            "id": f"mock_record_{1000000 + i}",
            "meeting_id": f"meeting_{1000000 + i}",
            "start_ts": meeting_start.strftime("%Y-%m-%d %H:%M:%S"),
            "end_ts": meeting_end.strftime("%Y-%m-%d %H:%M:%S"),
            "student_ids": participants,
            "phase": template["phase"],
            "transcript": template["transcript"],
            "summary": template["summary"],
            "play_url": f"https://demo.com/play/{1000000 + i}",
            "download_url": f"https://demo.com/download/{1000000 + i}",
            "status": "completed"
        }
        
        meetings.append(meeting)
    
    return meetings

def save_to_database(meetings):
    """ä¿å­˜ä¼šè®®æ•°æ®åˆ°æ•°æ®åº“"""
    try:
        conn = pymysql.connect(**DB_CONFIG, autocommit=True)
        
        with conn.cursor() as cursor:
            for meeting in meetings:
                # æ’å…¥ä¼šè®®è®°å½•
                insert_sql = """
                INSERT IGNORE INTO recordings 
                (id, meeting_id, start_ts, end_ts, student_ids, phase, transcript, summary, 
                 play_url, download_url, status)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                """
                
                cursor.execute(insert_sql, (
                    meeting['id'],
                    meeting['meeting_id'],
                    meeting['start_ts'],
                    meeting['end_ts'],
                    json.dumps(meeting['student_ids'], ensure_ascii=False),
                    meeting['phase'],
                    meeting['transcript'],
                    meeting['summary'],
                    meeting['play_url'],
                    meeting['download_url'],
                    meeting['status']
                ))
                
                # æ›´æ–°å­¦ç”Ÿç»Ÿè®¡
                for student_id in meeting['student_ids']:
                    if not student_id.startswith('teacher_'):
                        update_sql = """
                        INSERT INTO student_stats (student_id, record_cnt, last_record_at)
                        VALUES (%s, 1, %s)
                        ON DUPLICATE KEY UPDATE 
                        record_cnt = record_cnt + 1,
                        last_record_at = VALUES(last_record_at)
                        """
                        cursor.execute(update_sql, (student_id, meeting['start_ts']))
        
        conn.close()
        logger.info(f"æˆåŠŸä¿å­˜ {len(meetings)} æ¡ä¼šè®®è®°å½•åˆ°æ•°æ®åº“")
        
    except Exception as e:
        logger.error(f"æ•°æ®åº“ä¿å­˜å¤±è´¥: {e}")
        raise

def test_kimi_api():
    """æµ‹è¯•Kimi APIè¿æ¥"""
    try:
        import requests
        
        url = f"{KIMI_BASE_URL}/chat-messages"
        
        headers = {
            "Authorization": f"Bearer {KIMI_API_KEY}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "messages": [
                {
                    "role": "user",
                    "content": "ä½ å¥½ï¼Œè¯·ç®€å•å›å¤ä¸€ä¸‹æµ‹è¯•æ¶ˆæ¯ã€‚"
                }
            ],
            "stream": False
        }
        
        response = requests.post(url, json=payload, headers=headers, timeout=30)
        response.raise_for_status()
        data = response.json()
        
        logger.info("âœ… Kimi APIè¿æ¥æˆåŠŸ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ Kimi APIè¿æ¥å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹æ¼”ç¤ºå¤„ç†...")
    
    # æµ‹è¯•æ•°æ®åº“è¿æ¥
    try:
        conn = pymysql.connect(**DB_CONFIG)
        conn.close()
        logger.info("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        return
    
    # æµ‹è¯•Kimi API
    if test_kimi_api():
        logger.info("âœ… Kimi APIè¿æ¥æˆåŠŸ")
    else:
        logger.warning("âš ï¸ Kimi APIè¿æ¥å¤±è´¥ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
    
    # ç”Ÿæˆæ¨¡æ‹Ÿä¼šè®®æ•°æ®
    logger.info("ğŸ“Š ç”Ÿæˆæ¨¡æ‹Ÿä¼šè®®æ•°æ®...")
    meetings = generate_mock_meetings(20)  # ç”Ÿæˆ20æ¡è®°å½•
    
    # ä¿å­˜åˆ°æ•°æ®åº“
    logger.info("ğŸ’¾ ä¿å­˜æ•°æ®åˆ°æ•°æ®åº“...")
    save_to_database(meetings)
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    logger.info("ğŸ“ˆ æ•°æ®ç»Ÿè®¡:")
    logger.info(f"   - æ€»ä¼šè®®æ•°: {len(meetings)}")
    
    phase_stats = {}
    for meeting in meetings:
        phase = meeting['phase']
        phase_stats[phase] = phase_stats.get(phase, 0) + 1
    
    for phase, count in phase_stats.items():
        logger.info(f"   - {phase}: {count}æ¡")
    
    logger.info("âœ… æ¼”ç¤ºå¤„ç†å®Œæˆï¼")
    logger.info("ç°åœ¨å¯ä»¥è®¿é—®ç®¡ç†åå°æŸ¥çœ‹æ•°æ®: https://offercome2025-9g14jitp22f4ddfc-1256790827.tcloudbaseapp.com/admin-meetings-luxury.html")

if __name__ == "__main__":
    main() 